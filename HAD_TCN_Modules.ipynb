{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "HAD TCN Modules",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMwhmaFn9SLWCHjaKqdOdgb",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aishoo1612/HateAndAggressionDetection/blob/main/HAD_TCN_Modules.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNmq9fwWK2KL"
      },
      "source": [
        "# IMPORTING LIBRARIES AND SHIT\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nbsTUD4yVWl",
        "outputId": "765933b3-1df7-4255-aa15-35a5ee693c6c"
      },
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "import nltk\n",
        "import random\n",
        "# from nltk.tokenize import TweetTokenizer\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "%config IPCompleter.greedy=True\n",
        "%config IPCompleter.use_jedi=False\n",
        "# nltk.download('twitter_samples')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: UserWarning: Config option `use_jedi` not recognized by `IPCompleter`.\n",
            "  del sys.path[0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MR2IlXnHy1ww",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b44c8c7-f22d-4060-ffa5-b0dbd23ee26f"
      },
      "source": [
        "tf.config.list_physical_devices('GPU') "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U05oJ4Dnv-cj",
        "outputId": "3eb9b6e0-c667-424f-b719-e84817f07305"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KR7OHwXxv_UM"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Hate And aggression Detection/agr_en_train.csv')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ozBwsnFzHe9",
        "outputId": "7e09a786-b7fd-46d4-d0a1-44ba2c4c865f"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 12000 entries, 0 to 11999\n",
            "Data columns (total 2 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   Comments  12000 non-null  object\n",
            " 1   level     12000 non-null  int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 187.6+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "id": "64-_pnjtzMnL",
        "outputId": "da5a017a-d59e-456a-af82-a988e99bdc6b"
      },
      "source": [
        "\n",
        "df.groupby( by='level').count()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Comments</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>level</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2708</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Comments\n",
              "level          \n",
              "0          5052\n",
              "1          4240\n",
              "2          2708"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QH3yakkDzSS2"
      },
      "source": [
        "comments, level = list(df.Comments), list(df.level)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "noqaQxM8zbZG",
        "outputId": "47b6a12c-64f9-49be-f4fa-ae8cd70f4f21"
      },
      "source": [
        "\n",
        "comments[0]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Well said sonu..you have courage to stand against dadagiri of Muslims'"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_w_SIOt0FC3"
      },
      "source": [
        "# SECTION _ PREPROCESSING \n",
        "**Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfurcQy1zg8C"
      },
      "source": [
        "\n",
        "# Define a function to compute the max length of sequence\n",
        "def max_length(sequences):\n",
        "    '''\n",
        "    input:\n",
        "        sequences: a 2D list of integer sequences\n",
        "    output:\n",
        "        max_length: the max length of the sequences\n",
        "    '''\n",
        "    max_length = 0\n",
        "    for i, seq in enumerate(sequences):\n",
        "        length = len(seq)\n",
        "        if max_length < length:\n",
        "            max_length = length\n",
        "    return max_length"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01gVim54zzwT",
        "outputId": "11516e78-991d-4d5b-cd80-6b78e63f5aaf"
      },
      "source": [
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "trunc_type='post'\n",
        "padding_type='post'\n",
        "oov_tok = \"<UNK>\"\n",
        "\n",
        "print(\"Example of sentence: \", comments[4])\n",
        "\n",
        "# Cleaning and Tokenization\n",
        "tokenizer = Tokenizer(oov_token=oov_tok)\n",
        "tokenizer.fit_on_texts(comments)\n",
        "\n",
        "# Turn the text into sequence\n",
        "training_sequences = tokenizer.texts_to_sequences(comments)\n",
        "max_len = max_length(training_sequences)\n",
        "\n",
        "print('Into a sequence of int:', training_sequences[4])\n",
        "\n",
        "# Pad the sequence to have the same size\n",
        "training_padded = pad_sequences(training_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
        "print('Into a padded sequence:', training_padded[4])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example of sentence:  ??we r against cow slaughter,so of course it will stop leather manufacturing if it happens.\n",
            "Into a sequence of int: [21, 79, 94, 232, 2250, 40, 5, 1276, 14, 19, 146, 5335, 2006, 38, 14, 784]\n",
            "Into a padded sequence: [21 79 94 ...  0  0  0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FaO1xN-00Clf",
        "outputId": "dd54bbdd-7beb-4823-e261-b4dae3def33f"
      },
      "source": [
        "word_index = tokenizer.word_index\n",
        "# See the first 10 words in the vocabulary\n",
        "for i, word in enumerate(word_index):\n",
        "    print(word, word_index.get(word))\n",
        "    if i==9:\n",
        "        break\n",
        "vocab_size = len(word_index)+1\n",
        "print(vocab_size)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<UNK> 1\n",
            "the 2\n",
            "to 3\n",
            "and 4\n",
            "of 5\n",
            "is 6\n",
            "in 7\n",
            "a 8\n",
            "for 9\n",
            "are 10\n",
            "23376\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJUtAw6g0OPL"
      },
      "source": [
        "**Setting up the models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDmOv9vP0RKo"
      },
      "source": [
        "\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.constraints import MaxNorm\n",
        "from tensorflow.keras.layers import Input, Embedding, Conv1D, Dropout, MaxPool1D, Flatten, Dense, Bidirectional, GRU\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import concatenate"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLyk32oyxtnY"
      },
      "source": [
        "**CNN + BiGRU**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RaAFh9WjKftc"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pE_HFgGKgEH"
      },
      "source": [
        "# THIS IS THE CNN + BiGRU SECTION\n",
        "\n",
        "**DO NOT OVERRUN THEM. THEY TAKE OVER 5 HRS TO TRAIN >.<**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uc92DLmxQMl"
      },
      "source": [
        "def define_model(filters = 50, kernel_size = 3, activation='relu', input_dim = None, output_dim=300, max_length = None ):\n",
        "  \n",
        "    # Channel 1\n",
        "    input1 = Input(shape=(max_length,))\n",
        "    embeddding1 = Embedding(input_dim=input_dim, output_dim=output_dim, input_length=max_length)(input1)\n",
        "    conv1 = Conv1D(filters=filters, kernel_size=kernel_size, activation='relu', \n",
        "                   kernel_constraint= MaxNorm( max_value=3, axis=[0,1]))(embeddding1)\n",
        "    pool1 = MaxPool1D(pool_size=2, strides=2)(conv1)\n",
        "    flat1 = Flatten()(pool1)\n",
        "    drop1 = Dropout(0.5)(flat1)\n",
        "    dense1 = Dense(10, activation='relu')(drop1)\n",
        "    drop1 = Dropout(0.5)(dense1)\n",
        "    out1 = Dense(1, activation='sigmoid')(drop1)\n",
        "    \n",
        "    # Channel 2\n",
        "    input2 = Input(shape=(max_length,))\n",
        "    embeddding2 = Embedding(input_dim=input_dim, output_dim=output_dim, input_length=max_length, mask_zero=True)(input2)\n",
        "    gru2 = Bidirectional(GRU(64))(embeddding2)\n",
        "    drop2 = Dropout(0.5)(gru2)\n",
        "    out2 = Dense(1, activation='sigmoid')(drop2)\n",
        "    \n",
        "    # Merge\n",
        "    merged = concatenate([out1, out2])\n",
        "    \n",
        "    # Interpretation\n",
        "    outputs = Dense(1, activation='sigmoid')(merged)\n",
        "    model = Model(inputs=[input1, input2], outputs=outputs)\n",
        "    \n",
        "    # Compile\n",
        "    model.compile( loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VeH6-coZ0Unb",
        "outputId": "10a67bed-99ba-4e3a-95f1-b6c0d05197a9"
      },
      "source": [
        "\n",
        "model_0 = define_model( input_dim=1000, max_length=100)\n",
        "model_0.summary()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 100)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 100, 300)     300000      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d (Conv1D)                 (None, 98, 50)       45050       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D)    (None, 49, 50)       0           conv1d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 2450)         0           max_pooling1d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 100)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 2450)         0           flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 100, 300)     300000      input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           24510       dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   (None, 128)          140544      embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 10)           0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 128)          0           bidirectional[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1)            11          dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 1)            129         dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 2)            0           dense_1[0][0]                    \n",
            "                                                                 dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 1)            3           concatenate[0][0]                \n",
            "==================================================================================================\n",
            "Total params: 810,247\n",
            "Trainable params: 810,247\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nv3CV5F0hno"
      },
      "source": [
        "\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "    # Overide the method on_epoch_end() for our benefit\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if (logs.get('accuracy') > 0.5):\n",
        "            print(\"\\nReached 52% accuracy so cancelling training!\")\n",
        "            self.model.stop_training=True\n",
        "\n",
        "\n",
        "callbacks = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0, \n",
        "                                             patience=7, verbose=2, \n",
        "                                             mode='auto', restore_best_weights=True)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "LJOLAGXQ0m_l",
        "outputId": "50fc50f2-4673-4ae2-c455-7b6439e25a3e"
      },
      "source": [
        "# Parameter Initialization\n",
        "trunc_type='post'\n",
        "padding_type='post'\n",
        "oov_tok = \"<UNK>\"\n",
        "activations = ['relu']\n",
        "filters = 100\n",
        "kernel_sizes = [1, 2, 3, 4, 5, 6]\n",
        "\n",
        "columns = ['Activation', 'Filters', 'acc1', 'acc2', 'acc3', 'acc4', 'acc5', 'acc6', 'acc7', 'acc8', 'acc9', 'acc10', 'AVG']\n",
        "record = pd.DataFrame(columns = columns)\n",
        "\n",
        "# prepare cross validation with 10 splits and shuffle = True\n",
        "kfold = KFold(10, True)\n",
        "\n",
        "# Separate the sentences and the labels\n",
        "comments, level = list(df.Comments), list(df.level)\n",
        "\n",
        "for activation in activations:\n",
        "    for kernel_size in kernel_sizes:\n",
        "        # kfold.split() will return set indices for each split\n",
        "        acc_list = []\n",
        "        for train, test in kfold.split(comments):\n",
        "            \n",
        "            train_x, test_x = [], []\n",
        "            train_y, test_y = [], []\n",
        "            \n",
        "            for i in train:\n",
        "                train_x.append(comments[i])\n",
        "                train_y.append(level[i])\n",
        "\n",
        "            for i in test:\n",
        "                test_x.append(comments[i])\n",
        "                test_y.append(level[i])\n",
        "\n",
        "            # Turn the labels into a numpy array\n",
        "            train_y = np.array(train_y)\n",
        "            test_y = np.array(test_y)\n",
        "\n",
        "            # encode data using\n",
        "            # Cleaning and Tokenization\n",
        "            tokenizer = Tokenizer(oov_token=oov_tok)\n",
        "            tokenizer.fit_on_texts(train_x)\n",
        "\n",
        "            # Turn the text into sequence\n",
        "            training_sequences = tokenizer.texts_to_sequences(train_x)\n",
        "            test_sequences = tokenizer.texts_to_sequences(test_x)\n",
        "\n",
        "            max_len = max_length(training_sequences)\n",
        "\n",
        "            # Pad the sequence to have the same size\n",
        "            Xtrain = pad_sequences(training_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
        "            Xtest = pad_sequences(test_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "            word_index = tokenizer.word_index\n",
        "            vocab_size = len(word_index)+1\n",
        "            \n",
        "            # Define the input shape\n",
        "            model = define_model(filters, kernel_size, activation, input_dim=vocab_size, max_length=max_len)\n",
        "\n",
        "            # Train the model and initialize test accuracy with 0\n",
        "            acc = 0\n",
        "            while(acc<0.5):\n",
        "                \n",
        "                # Train the model\n",
        "                model.fit(x=[Xtrain, Xtrain], y = train_y, batch_size=50, epochs=100, verbose=1, \n",
        "                          callbacks=[callbacks], validation_data=([Xtest, Xtest], test_y))\n",
        "\n",
        "                # evaluate the model\n",
        "                loss, acc = model.evaluate([Xtest, Xtest], test_y, verbose=0)\n",
        "                print('Test Accuracy: {}'.format(acc*100))\n",
        "                \n",
        "                if (acc<0.5):\n",
        "                    print('The model suffered from local minimum. Retrain the model!')\n",
        "                    model = define_model(filters, kernel_size, activation, input_dim=vocab_size, max_length=max_len)\n",
        "                    \n",
        "                else:\n",
        "                    print('Done!')\n",
        "\n",
        "            # evaluate the model\n",
        "            loss, acc = model.evaluate([Xtest, Xtest], test_y, verbose=0)\n",
        "            print('Test Accuracy: {}'.format(acc*100))\n",
        "\n",
        "            acc_list.append(acc*100)\n",
        "            \n",
        "        mean_acc = np.array(acc_list).mean()\n",
        "        parameters = [activation, kernel_size]\n",
        "        entries = parameters + acc_list + [mean_acc]\n",
        "\n",
        "        temp = pd.DataFrame([entries], columns=columns)\n",
        "        record = record.append(temp, ignore_index=True)\n",
        "        print()\n",
        "        print(record)\n",
        "        print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy: 37.583333253860474\n",
            "The model suffered from local minimum. Retrain the model!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-386bf59cdea0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     72\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The model suffered from local minimum. Retrain the model!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m                     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefine_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-8084487c7b8d>\u001b[0m in \u001b[0;36mdefine_model\u001b[0;34m(filters, kernel_size, activation, input_dim, output_dim, max_length)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0minput2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0membeddding2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_zero\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mgru2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBidirectional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGRU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddding2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mdrop2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgru2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mout2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/wrappers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBidirectional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m     \u001b[0;31m# Applies the same workaround as in `RNN.__call__`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m--> 977\u001b[0;31m                                                 input_list)\n\u001b[0m\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m     \u001b[0;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1113\u001b[0m       \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m       outputs = self._keras_tensor_symbolic_call(\n\u001b[0;32m-> 1115\u001b[0;31m           inputs, input_masks, args, kwargs)\n\u001b[0m\u001b[1;32m   1116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1117\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    846\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    886\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m           \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/wrappers.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask, initial_state, constants)\u001b[0m\n\u001b[1;32m    699\u001b[0m                              initial_state=forward_state, **kwargs)\n\u001b[1;32m    700\u001b[0m       y_rev = self.backward_layer(backward_inputs,\n\u001b[0;32m--> 701\u001b[0;31m                                   initial_state=backward_state, **kwargs)\n\u001b[0m\u001b[1;32m    702\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m       \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m     \u001b[0;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1037\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/recurrent_v2.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m       last_output, outputs, runtime, states = self._defun_gru_call(\n\u001b[0;32m--> 444\u001b[0;31m           inputs, initial_state, training, mask, row_lengths)\n\u001b[0m\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/recurrent_v2.py\u001b[0m in \u001b[0;36m_defun_gru_call\u001b[0;34m(self, inputs, initial_state, training, mask, sequence_lengths)\u001b[0m\n\u001b[1;32m    519\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         last_output, outputs, new_h, runtime = gru_with_backend_selection(\n\u001b[0;32m--> 521\u001b[0;31m             **normal_gru_kwargs)\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m     \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnew_h\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/recurrent_v2.py\u001b[0m in \u001b[0;36mgru_with_backend_selection\u001b[0;34m(inputs, init_h, kernel, recurrent_kernel, bias, mask, time_major, go_backwards, sequence_lengths, zero_output_for_mask)\u001b[0m\n\u001b[1;32m    819\u001b[0m     \u001b[0;31m# grappler will kick in during session execution to optimize the graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m     \u001b[0mlast_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mruntime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefun_standard_gru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m     \u001b[0m_function_register\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefun_gpu_gru\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    822\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mlast_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mruntime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/recurrent_v2.py\u001b[0m in \u001b[0;36m_function_register\u001b[0;34m(func, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m   \u001b[0mconcrete_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1782\u001b[0m   \u001b[0mconcrete_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1783\u001b[0;31m   \u001b[0mconcrete_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_gradient_functions_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1784\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mconcrete_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36madd_gradient_functions_to_graph\u001b[0;34m(self, g)\u001b[0m\n\u001b[1;32m   2100\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2101\u001b[0m     forward_function, backward_function = (\n\u001b[0;32m-> 2102\u001b[0;31m         self._delayed_rewrite_functions.forward_backward())\n\u001b[0m\u001b[1;32m   2103\u001b[0m     \u001b[0mforward_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2104\u001b[0m     \u001b[0mbackward_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mforward_backward\u001b[0;34m(self, num_doutputs)\u001b[0m\n\u001b[1;32m    691\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mforward_backward\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mforward_backward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m     \u001b[0mforward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_construct_forward_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_doutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cached_function_pairs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum_doutputs\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_construct_forward_backward\u001b[0;34m(self, num_doutputs)\u001b[0m\n\u001b[1;32m    739\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m           \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 741\u001b[0;31m           func_graph=backwards_graph)\n\u001b[0m\u001b[1;32m    742\u001b[0m       \u001b[0mbackwards_graph_captures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackwards_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexternal_captures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m       captures_from_forward = [\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_backprop_function\u001b[0;34m(*grad_ys)\u001b[0m\n\u001b[1;32m    729\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m             \u001b[0mgrad_ys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrad_ys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 731\u001b[0;31m             src_graph=self._func_graph)\n\u001b[0m\u001b[1;32m    732\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m_GradientsHelper\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\u001b[0m\n\u001b[1;32m    680\u001b[0m                 \u001b[0;31m# functions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m                 in_grads = _MaybeCompile(grad_scope, op, func_call,\n\u001b[0;32m--> 682\u001b[0;31m                                          lambda: grad_fn(op, *out_grads))\n\u001b[0m\u001b[1;32m    683\u001b[0m               \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m                 \u001b[0;31m# For function call ops, we add a 'SymbolicGradient'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m_MaybeCompile\u001b[0;34m(scope, op, func, grad_fn)\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mxla_compile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Exit early\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m   \u001b[0;31m# If the gradients are supposed to be compiled separately, we give them a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    680\u001b[0m                 \u001b[0;31m# functions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m                 in_grads = _MaybeCompile(grad_scope, op, func_call,\n\u001b[0;32m--> 682\u001b[0;31m                                          lambda: grad_fn(op, *out_grads))\n\u001b[0m\u001b[1;32m    683\u001b[0m               \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m                 \u001b[0;31m# For function call ops, we add a 'SymbolicGradient'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/cond_v2.py\u001b[0m in \u001b[0;36m_IfGrad\u001b[0;34m(op, *grads)\u001b[0m\n\u001b[1;32m    186\u001b[0m       \u001b[0mtrue_grad_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m       \u001b[0mfalse_grad_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m       \u001b[0mbuilding_gradient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m   )\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/cond_v2.py\u001b[0m in \u001b[0;36m_build_cond\u001b[0;34m(pred, true_graph, false_graph, true_inputs, false_inputs, building_gradient, name)\u001b[0m\n\u001b[1;32m    228\u001b[0m   \u001b[0;31m# this modifies true_graph and false_graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m   cond_inputs = _make_inputs_match([true_graph, false_graph],\n\u001b[0;32m--> 230\u001b[0;31m                                    [true_inputs, false_inputs])\n\u001b[0m\u001b[1;32m    231\u001b[0m   \u001b[0;31m# We do not output intermediates of the gradient If op since this is just\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m   \u001b[0;31m# for backwards compatibility with existing code.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/cond_v2.py\u001b[0m in \u001b[0;36m_make_inputs_match\u001b[0;34m(branch_graphs, branch_inputs)\u001b[0m\n\u001b[1;32m    540\u001b[0m       \u001b[0mparam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbranch_input_to_param\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m         \u001b[0mparam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_create_dummy_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbranch_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m       \u001b[0minput_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/cond_v2.py\u001b[0m in \u001b[0;36m_create_dummy_input\u001b[0;34m(func_graph, template_tensor)\u001b[0m\n\u001b[1;32m    737\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mfunc_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m     return array_ops.placeholder(\n\u001b[0;32m--> 739\u001b[0;31m         template_tensor.dtype, shape=template_tensor.shape)\n\u001b[0m\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mplaceholder\u001b[0;34m(dtype, shape, name)\u001b[0m\n\u001b[1;32m   3283\u001b[0m                        \"eager execution.\")\n\u001b[1;32m   3284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3285\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mplaceholder\u001b[0;34m(dtype, shape, name)\u001b[0m\n\u001b[1;32m   6727\u001b[0m   \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"shape\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6728\u001b[0m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0;32m-> 6729\u001b[0;31m         \"Placeholder\", dtype=dtype, shape=shape, name=name)\n\u001b[0m\u001b[1;32m   6730\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6731\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    748\u001b[0m       op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n\u001b[1;32m    749\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m                                  attrs=attr_protos, op_def=op_def)\n\u001b[0m\u001b[1;32m    751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m     \u001b[0;31m# `outputs` is returned as a separate return value so that the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    599\u001b[0m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[1;32m    600\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m         compute_device)\n\u001b[0m\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3552\u001b[0m       \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3554\u001b[0;31m     \u001b[0mnode_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_NodeDef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3556\u001b[0m     \u001b[0minput_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_NodeDef\u001b[0;34m(op_type, name, attrs)\u001b[0m\n\u001b[1;32m   1818\u001b[0m                                   name=compat.as_bytes(name))\n\u001b[1;32m   1819\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1820\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1821\u001b[0m       \u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mnode_def\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/six.py\u001b[0m in \u001b[0;36miteritems\u001b[0;34m(d, **kw)\u001b[0m\n\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0miterlists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SI8rBbmIx_7i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "outputId": "3562d679-d3f2-4b28-f888-7f919428ff21"
      },
      "source": [
        "\n",
        "record.sort_values(by='AVG', ascending=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Activation</th>\n",
              "      <th>Filters</th>\n",
              "      <th>acc1</th>\n",
              "      <th>acc2</th>\n",
              "      <th>acc3</th>\n",
              "      <th>acc4</th>\n",
              "      <th>acc5</th>\n",
              "      <th>acc6</th>\n",
              "      <th>acc7</th>\n",
              "      <th>acc8</th>\n",
              "      <th>acc9</th>\n",
              "      <th>acc10</th>\n",
              "      <th>AVG</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>relu</td>\n",
              "      <td>1</td>\n",
              "      <td>54.083335</td>\n",
              "      <td>51.499999</td>\n",
              "      <td>51.583332</td>\n",
              "      <td>51.583332</td>\n",
              "      <td>54.833335</td>\n",
              "      <td>53.666669</td>\n",
              "      <td>53.666669</td>\n",
              "      <td>51.583332</td>\n",
              "      <td>51.833332</td>\n",
              "      <td>51.166666</td>\n",
              "      <td>52.55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>relu</td>\n",
              "      <td>2</td>\n",
              "      <td>53.250003</td>\n",
              "      <td>51.416665</td>\n",
              "      <td>52.666664</td>\n",
              "      <td>51.333332</td>\n",
              "      <td>53.166670</td>\n",
              "      <td>54.583335</td>\n",
              "      <td>52.333331</td>\n",
              "      <td>52.833331</td>\n",
              "      <td>50.749999</td>\n",
              "      <td>53.166670</td>\n",
              "      <td>52.55</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Activation Filters       acc1  ...       acc9      acc10    AVG\n",
              "0       relu       1  54.083335  ...  51.833332  51.166666  52.55\n",
              "1       relu       2  53.250003  ...  50.749999  53.166670  52.55\n",
              "\n",
              "[2 rows x 13 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxPlBtJjAx4N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "outputId": "2677ac88-96fc-4986-b8d3-36b5e9284d7c"
      },
      "source": [
        "record[['Activation', 'AVG']].groupby(by='Activation').max().sort_values(by='AVG', ascending=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AVG</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Activation</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>relu</th>\n",
              "      <td>52.55</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              AVG\n",
              "Activation       \n",
              "relu        52.55"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-O81-CTA1jP"
      },
      "source": [
        "report = record.sort_values(by='AVG', ascending=False)\n",
        "report = report.to_excel('HYBRID_CR.xlsx', sheet_name='random')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsVxZKliA-vc"
      },
      "source": [
        "**tcn**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "miYfOKewKC1x"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1maet-vKD27"
      },
      "source": [
        "# Temporal Convolutional Networks Below\n",
        "**DO NOT OVER RUN THEM. THEY TAKE OVER 4.5 HRS TO TRAIN**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5Irx6R1KCnA"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4mZoKsdKCa6"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DIrJhyItGfJu",
        "outputId": "ca16c600-a0a8-4d83-a943-df07a5d24df9"
      },
      "source": [
        "!pip install keras-tcn\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras-tcn\n",
            "  Downloading keras_tcn-3.4.0-py2.py3-none-any.whl (13 kB)\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.14.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 8.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from keras-tcn) (2.6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-tcn) (1.19.5)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (1.12.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.37.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (1.39.0)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (3.1.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (3.3.0)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (0.4.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (1.1.2)\n",
            "Requirement already satisfied: keras~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (2.6.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (0.37.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (0.2.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-estimator~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (2.6.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (3.17.3)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (0.12.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (3.7.4.3)\n",
            "Requirement already satisfied: clang~=5.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (5.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (1.12)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (2.6.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (1.1.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow->keras-tcn) (1.5.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->keras-tcn) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->keras-tcn) (1.8.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->keras-tcn) (57.4.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->keras-tcn) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->keras-tcn) (0.4.5)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->keras-tcn) (0.6.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->keras-tcn) (1.34.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->keras-tcn) (3.3.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow->keras-tcn) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow->keras-tcn) (4.2.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow->keras-tcn) (4.7.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow->keras-tcn) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow->keras-tcn) (4.6.4)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow->keras-tcn) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow->keras-tcn) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow->keras-tcn) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow->keras-tcn) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow->keras-tcn) (2021.5.30)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow->keras-tcn) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.6->tensorflow->keras-tcn) (3.5.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->keras-tcn) (2.7.1)\n",
            "Installing collected packages: tensorflow-addons, keras-tcn\n",
            "Successfully installed keras-tcn-3.4.0 tensorflow-addons-0.14.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "183iaDOBA-NK"
      },
      "source": [
        "from tcn import TCN, tcn_full_summary\n",
        "from tensorflow.keras.layers import Input, Embedding, Dense, Dropout, SpatialDropout1D\n",
        "from tensorflow.keras.layers import concatenate, GlobalAveragePooling1D, GlobalMaxPooling1D\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "def define_model(kernel_size = 3, activation='relu', input_dim = None, output_dim=300, max_length = None ):\n",
        "    \n",
        "    inp = Input( shape=(max_length,))\n",
        "    x = Embedding(input_dim=input_dim, output_dim=output_dim, input_length=max_length)(inp)\n",
        "    x = SpatialDropout1D(0.1)(x)\n",
        "    \n",
        "    x = TCN(128,dilations = [1, 2, 4], return_sequences=True, activation = activation, name = 'tcn1')(x)\n",
        "    x = TCN(64,dilations = [1, 2, 4], return_sequences=True, activation = activation, name = 'tcn2')(x)\n",
        "    \n",
        "    avg_pool = GlobalAveragePooling1D()(x)\n",
        "    max_pool = GlobalMaxPooling1D()(x)\n",
        "    \n",
        "    conc = concatenate([avg_pool, max_pool])\n",
        "    conc = Dense(16, activation=\"relu\")(conc)\n",
        "    conc = Dropout(0.1)(conc)\n",
        "    outp = Dense(1, activation=\"sigmoid\")(conc)    \n",
        "\n",
        "    model = Model(inputs=inp, outputs=outp)\n",
        "    model.compile( loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "    \n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1GXc3HQBF4n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d735f174-2ac0-450d-cc56-6f44ad7ac78f"
      },
      "source": [
        "model_0 = define_model( input_dim=1000, max_length=100)\n",
        "model_0.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 100)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 100, 300)     300000      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "spatial_dropout1d (SpatialDropo (None, 100, 300)     0           embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tcn1 (TCN)                      (None, 100, 128)     400256      spatial_dropout1d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tcn2 (TCN)                      (None, 100, 64)      94656       tcn1[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d (Globa (None, 64)           0           tcn2[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d (GlobalMax (None, 64)           0           tcn2[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 128)          0           global_average_pooling1d[0][0]   \n",
            "                                                                 global_max_pooling1d[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 16)           2064        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 16)           0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1)            17          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 796,993\n",
            "Trainable params: 796,993\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OGalfd2GxFk"
      },
      "source": [
        "\n",
        "callbacks = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0, \n",
        "                                             patience=10, verbose=2, \n",
        "                                             mode='auto', restore_best_weights=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zoD5IhdKG04s",
        "outputId": "4d6dca28-6903-4917-f9a1-dc09a08d6b27"
      },
      "source": [
        "trunc_type='post'\n",
        "padding_type='post'\n",
        "oov_tok = \"<UNK>\"\n",
        "activations = ['relu', 'tanh']\n",
        "kernel_sizes = [1, 2, 3 , 4 , 5 , 6]\n",
        "\n",
        "columns = ['Activation', 'Filters', 'acc1', 'acc2', 'acc3', 'acc4', 'acc5', 'acc6', 'acc7', 'acc8', 'acc9', 'acc10', 'AVG']\n",
        "record = pd.DataFrame(columns = columns)\n",
        "\n",
        "# prepare cross validation with 10 splits and shuffle = True\n",
        "kfold = KFold(10, True)\n",
        "\n",
        "# Separate the sentences and the labels\n",
        "comments, level = list(df.Comments), list(df.level)\n",
        "\n",
        "exp = 0\n",
        "\n",
        "for activation in activations:\n",
        "    for kernel_size in kernel_sizes:\n",
        "        # kfold.split() will return set indices for each split\n",
        "        exp+=1\n",
        "        print('-------------------------------------------')\n",
        "        print('Training {}: {} activation, {} kernel size.'.format(exp, activation, kernel_size))\n",
        "        print('-------------------------------------------')\n",
        "        acc_list = []\n",
        "        for train, test in kfold.split(comments):\n",
        "            \n",
        "            train_x, test_x = [], []\n",
        "            train_y, test_y = [], []\n",
        "            \n",
        "            for i in train:\n",
        "                train_x.append(comments[i])\n",
        "                train_y.append(level[i])\n",
        "\n",
        "            for i in test:\n",
        "                test_x.append(comments[i])\n",
        "                test_y.append(level[i])\n",
        "\n",
        "            # Turn the labels into a numpy array\n",
        "            train_y = np.array(train_y)\n",
        "            test_y = np.array(test_y)\n",
        "\n",
        "            # encode data using\n",
        "            # Cleaning and Tokenization\n",
        "            tokenizer = Tokenizer(oov_token=oov_tok)\n",
        "            tokenizer.fit_on_texts(train_x)\n",
        "\n",
        "            # Turn the text into sequence\n",
        "            training_sequences = tokenizer.texts_to_sequences(train_x)\n",
        "            test_sequences = tokenizer.texts_to_sequences(test_x)\n",
        "\n",
        "            max_len = max_length(training_sequences)\n",
        "\n",
        "            # Pad the sequence to have the same size\n",
        "            Xtrain = pad_sequences(training_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
        "            Xtest = pad_sequences(test_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "            word_index = tokenizer.word_index\n",
        "            vocab_size = len(word_index)+1\n",
        "\n",
        "            # Define the input shape\n",
        "            model = define_model(kernel_size, activation, input_dim=vocab_size, max_length=max_len)\n",
        "\n",
        "            # Train the model\n",
        "            model.fit(Xtrain, train_y, batch_size=50, epochs=100, verbose=2, \n",
        "                      callbacks=[callbacks], validation_data=(Xtest, test_y))\n",
        "\n",
        "            # evaluate the model\n",
        "            loss, acc = model.evaluate(Xtest, test_y, verbose=0)\n",
        "            print('Test Accuracy: {}'.format(acc*100))\n",
        "\n",
        "            acc_list.append(acc*100)\n",
        "            \n",
        "        mean_acc = np.array(acc_list).mean()\n",
        "        parameters = [activation, kernel_size]\n",
        "        entries = parameters + acc_list + [mean_acc]\n",
        "\n",
        "        temp = pd.DataFrame([entries], columns=columns)\n",
        "        record = record.append(temp, ignore_index=True)\n",
        "        print()\n",
        "        print(record)\n",
        "        print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------\n",
            "Training 1: relu activation, 1 kernel size.\n",
            "-------------------------------------------\n",
            "Epoch 1/100\n",
            "216/216 - 53s - loss: -4.3817e+13 - accuracy: 0.3940 - val_loss: -2.6234e+15 - val_accuracy: 0.4667\n",
            "Epoch 2/100\n",
            "216/216 - 19s - loss: nan - accuracy: 0.4350 - val_loss: nan - val_accuracy: 0.4175\n",
            "Epoch 3/100\n",
            "216/216 - 19s - loss: nan - accuracy: 0.4214 - val_loss: nan - val_accuracy: 0.4175\n",
            "Epoch 4/100\n",
            "216/216 - 19s - loss: nan - accuracy: 0.4214 - val_loss: nan - val_accuracy: 0.4175\n",
            "Epoch 5/100\n",
            "216/216 - 20s - loss: nan - accuracy: 0.4214 - val_loss: nan - val_accuracy: 0.4175\n",
            "Epoch 6/100\n",
            "216/216 - 20s - loss: nan - accuracy: 0.4214 - val_loss: nan - val_accuracy: 0.4175\n",
            "Epoch 7/100\n",
            "216/216 - 20s - loss: nan - accuracy: 0.4214 - val_loss: nan - val_accuracy: 0.4175\n",
            "Epoch 8/100\n",
            "216/216 - 20s - loss: nan - accuracy: 0.4214 - val_loss: nan - val_accuracy: 0.4175\n",
            "Epoch 9/100\n",
            "216/216 - 20s - loss: nan - accuracy: 0.4214 - val_loss: nan - val_accuracy: 0.4175\n",
            "Epoch 10/100\n",
            "216/216 - 20s - loss: nan - accuracy: 0.4214 - val_loss: nan - val_accuracy: 0.4175\n",
            "Epoch 11/100\n",
            "216/216 - 20s - loss: nan - accuracy: 0.4214 - val_loss: nan - val_accuracy: 0.4175\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00011: early stopping\n",
            "Test Accuracy: 46.666666865348816\n",
            "Epoch 1/100\n",
            "216/216 - 29s - loss: -1.9780e+14 - accuracy: 0.3886 - val_loss: -6.3848e+15 - val_accuracy: 0.4683\n",
            "Epoch 2/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4417 - val_loss: nan - val_accuracy: 0.4150\n",
            "Epoch 3/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4217 - val_loss: nan - val_accuracy: 0.4150\n",
            "Epoch 4/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4217 - val_loss: nan - val_accuracy: 0.4150\n",
            "Epoch 5/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4217 - val_loss: nan - val_accuracy: 0.4150\n",
            "Epoch 6/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4217 - val_loss: nan - val_accuracy: 0.4150\n",
            "Epoch 7/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4217 - val_loss: nan - val_accuracy: 0.4150\n",
            "Epoch 8/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4217 - val_loss: nan - val_accuracy: 0.4150\n",
            "Epoch 9/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4217 - val_loss: nan - val_accuracy: 0.4150\n",
            "Epoch 10/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4217 - val_loss: nan - val_accuracy: 0.4150\n",
            "Epoch 11/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4217 - val_loss: nan - val_accuracy: 0.4150\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00011: early stopping\n",
            "Test Accuracy: 46.83333337306976\n",
            "Epoch 1/100\n",
            "216/216 - 28s - loss: -1.6076e+13 - accuracy: 0.3794 - val_loss: -8.7649e+14 - val_accuracy: 0.4208\n",
            "Epoch 2/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4309 - val_loss: nan - val_accuracy: 0.4117\n",
            "Epoch 3/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4220 - val_loss: nan - val_accuracy: 0.4117\n",
            "Epoch 4/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4220 - val_loss: nan - val_accuracy: 0.4117\n",
            "Epoch 5/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4220 - val_loss: nan - val_accuracy: 0.4117\n",
            "Epoch 6/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4220 - val_loss: nan - val_accuracy: 0.4117\n",
            "Epoch 7/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4220 - val_loss: nan - val_accuracy: 0.4117\n",
            "Epoch 8/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4220 - val_loss: nan - val_accuracy: 0.4117\n",
            "Epoch 9/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4220 - val_loss: nan - val_accuracy: 0.4117\n",
            "Epoch 10/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4220 - val_loss: nan - val_accuracy: 0.4117\n",
            "Epoch 11/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4220 - val_loss: nan - val_accuracy: 0.4117\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00011: early stopping\n",
            "Test Accuracy: 42.08333194255829\n",
            "Epoch 1/100\n",
            "216/216 - 28s - loss: -4.4186e+11 - accuracy: 0.3838 - val_loss: -2.8322e+13 - val_accuracy: 0.4283\n",
            "Epoch 2/100\n",
            "216/216 - 26s - loss: nan - accuracy: 0.4406 - val_loss: nan - val_accuracy: 0.4117\n",
            "Epoch 3/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4220 - val_loss: nan - val_accuracy: 0.4117\n",
            "Epoch 4/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4220 - val_loss: nan - val_accuracy: 0.4117\n",
            "Epoch 5/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4220 - val_loss: nan - val_accuracy: 0.4117\n",
            "Epoch 6/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4220 - val_loss: nan - val_accuracy: 0.4117\n",
            "Epoch 7/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4220 - val_loss: nan - val_accuracy: 0.4117\n",
            "Epoch 8/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4220 - val_loss: nan - val_accuracy: 0.4117\n",
            "Epoch 9/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4220 - val_loss: nan - val_accuracy: 0.4117\n",
            "Epoch 10/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4220 - val_loss: nan - val_accuracy: 0.4117\n",
            "Epoch 11/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4220 - val_loss: nan - val_accuracy: 0.4117\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00011: early stopping\n",
            "Test Accuracy: 42.83333420753479\n",
            "Epoch 1/100\n",
            "216/216 - 28s - loss: -1.3519e+14 - accuracy: 0.3901 - val_loss: -7.5937e+15 - val_accuracy: 0.4858\n",
            "Epoch 2/100\n",
            "216/216 - 26s - loss: nan - accuracy: 0.4241 - val_loss: nan - val_accuracy: 0.4217\n",
            "Epoch 3/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4209 - val_loss: nan - val_accuracy: 0.4217\n",
            "Epoch 4/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4209 - val_loss: nan - val_accuracy: 0.4217\n",
            "Epoch 5/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4209 - val_loss: nan - val_accuracy: 0.4217\n",
            "Epoch 6/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4209 - val_loss: nan - val_accuracy: 0.4217\n",
            "Epoch 7/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4209 - val_loss: nan - val_accuracy: 0.4217\n",
            "Epoch 8/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4209 - val_loss: nan - val_accuracy: 0.4217\n",
            "Epoch 9/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4209 - val_loss: nan - val_accuracy: 0.4217\n",
            "Epoch 10/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4209 - val_loss: nan - val_accuracy: 0.4217\n",
            "Epoch 11/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4209 - val_loss: nan - val_accuracy: 0.4217\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00011: early stopping\n",
            "Test Accuracy: 48.58333468437195\n",
            "Epoch 1/100\n",
            "216/216 - 28s - loss: -5.7343e+13 - accuracy: 0.3949 - val_loss: -3.3525e+15 - val_accuracy: 0.4742\n",
            "Epoch 2/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4301 - val_loss: nan - val_accuracy: 0.4317\n",
            "Epoch 3/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4198 - val_loss: nan - val_accuracy: 0.4317\n",
            "Epoch 4/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4198 - val_loss: nan - val_accuracy: 0.4317\n",
            "Epoch 5/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4198 - val_loss: nan - val_accuracy: 0.4317\n",
            "Epoch 6/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4198 - val_loss: nan - val_accuracy: 0.4317\n",
            "Epoch 7/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4198 - val_loss: nan - val_accuracy: 0.4317\n",
            "Epoch 8/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4198 - val_loss: nan - val_accuracy: 0.4317\n",
            "Epoch 9/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4198 - val_loss: nan - val_accuracy: 0.4317\n",
            "Epoch 10/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4198 - val_loss: nan - val_accuracy: 0.4317\n",
            "Epoch 11/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4198 - val_loss: nan - val_accuracy: 0.4317\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00011: early stopping\n",
            "Test Accuracy: 47.41666615009308\n",
            "Epoch 1/100\n",
            "216/216 - 28s - loss: -7.5824e+14 - accuracy: 0.4012 - val_loss: -3.1737e+16 - val_accuracy: 0.4758\n",
            "Epoch 2/100\n",
            "216/216 - 26s - loss: nan - accuracy: 0.4290 - val_loss: nan - val_accuracy: 0.4350\n",
            "Epoch 3/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4194 - val_loss: nan - val_accuracy: 0.4350\n",
            "Epoch 4/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4194 - val_loss: nan - val_accuracy: 0.4350\n",
            "Epoch 5/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4194 - val_loss: nan - val_accuracy: 0.4350\n",
            "Epoch 6/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4194 - val_loss: nan - val_accuracy: 0.4350\n",
            "Epoch 7/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4194 - val_loss: nan - val_accuracy: 0.4350\n",
            "Epoch 8/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4194 - val_loss: nan - val_accuracy: 0.4350\n",
            "Epoch 9/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4194 - val_loss: nan - val_accuracy: 0.4350\n",
            "Epoch 10/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4194 - val_loss: nan - val_accuracy: 0.4350\n",
            "Epoch 11/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4194 - val_loss: nan - val_accuracy: 0.4350\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00011: early stopping\n",
            "Test Accuracy: 47.583332657814026\n",
            "Epoch 1/100\n",
            "216/216 - 28s - loss: -4.6965e+13 - accuracy: 0.3798 - val_loss: -2.5617e+15 - val_accuracy: 0.4817\n",
            "Epoch 2/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4337 - val_loss: nan - val_accuracy: 0.4133\n",
            "Epoch 3/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4219 - val_loss: nan - val_accuracy: 0.4133\n",
            "Epoch 4/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4219 - val_loss: nan - val_accuracy: 0.4133\n",
            "Epoch 5/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4219 - val_loss: nan - val_accuracy: 0.4133\n",
            "Epoch 6/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4219 - val_loss: nan - val_accuracy: 0.4133\n",
            "Epoch 7/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4219 - val_loss: nan - val_accuracy: 0.4133\n",
            "Epoch 8/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4219 - val_loss: nan - val_accuracy: 0.4133\n",
            "Epoch 9/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4219 - val_loss: nan - val_accuracy: 0.4133\n",
            "Epoch 10/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4219 - val_loss: nan - val_accuracy: 0.4133\n",
            "Epoch 11/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4219 - val_loss: nan - val_accuracy: 0.4133\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00011: early stopping\n",
            "Test Accuracy: 48.16666543483734\n",
            "Epoch 1/100\n",
            "216/216 - 28s - loss: -3.2145e+13 - accuracy: 0.3994 - val_loss: -1.1798e+15 - val_accuracy: 0.4875\n",
            "Epoch 2/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4406 - val_loss: nan - val_accuracy: 0.4258\n",
            "Epoch 3/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4205 - val_loss: nan - val_accuracy: 0.4258\n",
            "Epoch 4/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4205 - val_loss: nan - val_accuracy: 0.4258\n",
            "Epoch 5/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4205 - val_loss: nan - val_accuracy: 0.4258\n",
            "Epoch 6/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4205 - val_loss: nan - val_accuracy: 0.4258\n",
            "Epoch 7/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4205 - val_loss: nan - val_accuracy: 0.4258\n",
            "Epoch 8/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4205 - val_loss: nan - val_accuracy: 0.4258\n",
            "Epoch 9/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4205 - val_loss: nan - val_accuracy: 0.4258\n",
            "Epoch 10/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4205 - val_loss: nan - val_accuracy: 0.4258\n",
            "Epoch 11/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4205 - val_loss: nan - val_accuracy: 0.4258\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00011: early stopping\n",
            "Test Accuracy: 48.750001192092896\n",
            "Epoch 1/100\n",
            "216/216 - 28s - loss: -1.5137e+14 - accuracy: 0.3868 - val_loss: -4.6492e+15 - val_accuracy: 0.4742\n",
            "Epoch 2/100\n",
            "216/216 - 26s - loss: nan - accuracy: 0.4313 - val_loss: nan - val_accuracy: 0.4267\n",
            "Epoch 3/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4204 - val_loss: nan - val_accuracy: 0.4267\n",
            "Epoch 4/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4204 - val_loss: nan - val_accuracy: 0.4267\n",
            "Epoch 5/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4204 - val_loss: nan - val_accuracy: 0.4267\n",
            "Epoch 6/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4204 - val_loss: nan - val_accuracy: 0.4267\n",
            "Epoch 7/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4204 - val_loss: nan - val_accuracy: 0.4267\n",
            "Epoch 8/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4204 - val_loss: nan - val_accuracy: 0.4267\n",
            "Epoch 9/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4204 - val_loss: nan - val_accuracy: 0.4267\n",
            "Epoch 10/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4204 - val_loss: nan - val_accuracy: 0.4267\n",
            "Epoch 11/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4204 - val_loss: nan - val_accuracy: 0.4267\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00011: early stopping\n",
            "Test Accuracy: 47.41666615009308\n",
            "\n",
            "  Activation Filters       acc1  ...       acc9      acc10        AVG\n",
            "0       relu       1  46.666667  ...  48.750001  47.416666  46.633333\n",
            "\n",
            "[1 rows x 13 columns]\n",
            "\n",
            "-------------------------------------------\n",
            "Training 2: relu activation, 2 kernel size.\n",
            "-------------------------------------------\n",
            "Epoch 1/100\n",
            "216/216 - 23s - loss: -5.8302e+13 - accuracy: 0.4081 - val_loss: -2.7705e+15 - val_accuracy: 0.4717\n",
            "Epoch 2/100\n",
            "216/216 - 20s - loss: nan - accuracy: 0.4344 - val_loss: nan - val_accuracy: 0.4308\n",
            "Epoch 3/100\n",
            "216/216 - 20s - loss: nan - accuracy: 0.4199 - val_loss: nan - val_accuracy: 0.4308\n",
            "Epoch 4/100\n",
            "216/216 - 20s - loss: nan - accuracy: 0.4199 - val_loss: nan - val_accuracy: 0.4308\n",
            "Epoch 5/100\n",
            "216/216 - 20s - loss: nan - accuracy: 0.4199 - val_loss: nan - val_accuracy: 0.4308\n",
            "Epoch 6/100\n",
            "216/216 - 20s - loss: nan - accuracy: 0.4199 - val_loss: nan - val_accuracy: 0.4308\n",
            "Epoch 7/100\n",
            "216/216 - 20s - loss: nan - accuracy: 0.4199 - val_loss: nan - val_accuracy: 0.4308\n",
            "Epoch 8/100\n",
            "216/216 - 20s - loss: nan - accuracy: 0.4199 - val_loss: nan - val_accuracy: 0.4308\n",
            "Epoch 9/100\n",
            "216/216 - 20s - loss: nan - accuracy: 0.4199 - val_loss: nan - val_accuracy: 0.4308\n",
            "Epoch 10/100\n",
            "216/216 - 20s - loss: nan - accuracy: 0.4199 - val_loss: nan - val_accuracy: 0.4308\n",
            "Epoch 11/100\n",
            "216/216 - 20s - loss: nan - accuracy: 0.4199 - val_loss: nan - val_accuracy: 0.4308\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00011: early stopping\n",
            "Test Accuracy: 47.16666638851166\n",
            "Epoch 1/100\n",
            "216/216 - 28s - loss: -1.5155e+14 - accuracy: 0.3958 - val_loss: -6.8274e+15 - val_accuracy: 0.4792\n",
            "Epoch 2/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4413 - val_loss: nan - val_accuracy: 0.4267\n",
            "Epoch 3/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4204 - val_loss: nan - val_accuracy: 0.4267\n",
            "Epoch 4/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4204 - val_loss: nan - val_accuracy: 0.4267\n",
            "Epoch 5/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4204 - val_loss: nan - val_accuracy: 0.4267\n",
            "Epoch 6/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4204 - val_loss: nan - val_accuracy: 0.4267\n",
            "Epoch 7/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4204 - val_loss: nan - val_accuracy: 0.4267\n",
            "Epoch 8/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4204 - val_loss: nan - val_accuracy: 0.4267\n",
            "Epoch 9/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4204 - val_loss: nan - val_accuracy: 0.4267\n",
            "Epoch 10/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4204 - val_loss: nan - val_accuracy: 0.4267\n",
            "Epoch 11/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4204 - val_loss: nan - val_accuracy: 0.4267\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00011: early stopping\n",
            "Test Accuracy: 47.91666567325592\n",
            "Epoch 1/100\n",
            "216/216 - 28s - loss: -1.8442e+13 - accuracy: 0.3957 - val_loss: -1.0323e+15 - val_accuracy: 0.4758\n",
            "Epoch 2/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4298 - val_loss: nan - val_accuracy: 0.4317\n",
            "Epoch 3/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4198 - val_loss: nan - val_accuracy: 0.4317\n",
            "Epoch 4/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4198 - val_loss: nan - val_accuracy: 0.4317\n",
            "Epoch 5/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4198 - val_loss: nan - val_accuracy: 0.4317\n",
            "Epoch 6/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4198 - val_loss: nan - val_accuracy: 0.4317\n",
            "Epoch 7/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4198 - val_loss: nan - val_accuracy: 0.4317\n",
            "Epoch 8/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4198 - val_loss: nan - val_accuracy: 0.4317\n",
            "Epoch 9/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4198 - val_loss: nan - val_accuracy: 0.4317\n",
            "Epoch 10/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4198 - val_loss: nan - val_accuracy: 0.4317\n",
            "Epoch 11/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4198 - val_loss: nan - val_accuracy: 0.4317\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00011: early stopping\n",
            "Test Accuracy: 47.583332657814026\n",
            "Epoch 1/100\n",
            "216/216 - 29s - loss: -1.1503e+12 - accuracy: 0.3836 - val_loss: -2.0067e+14 - val_accuracy: 0.4975\n",
            "Epoch 2/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4453 - val_loss: nan - val_accuracy: 0.4200\n",
            "Epoch 3/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4211 - val_loss: nan - val_accuracy: 0.4200\n",
            "Epoch 4/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4211 - val_loss: nan - val_accuracy: 0.4200\n",
            "Epoch 5/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4211 - val_loss: nan - val_accuracy: 0.4200\n",
            "Epoch 6/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4211 - val_loss: nan - val_accuracy: 0.4200\n",
            "Epoch 7/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4211 - val_loss: nan - val_accuracy: 0.4200\n",
            "Epoch 8/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4211 - val_loss: nan - val_accuracy: 0.4200\n",
            "Epoch 9/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4211 - val_loss: nan - val_accuracy: 0.4200\n",
            "Epoch 10/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4211 - val_loss: nan - val_accuracy: 0.4200\n",
            "Epoch 11/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4211 - val_loss: nan - val_accuracy: 0.4200\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00011: early stopping\n",
            "Test Accuracy: 49.75000023841858\n",
            "Epoch 1/100\n",
            "216/216 - 28s - loss: -3.3420e+14 - accuracy: 0.3943 - val_loss: -1.2876e+16 - val_accuracy: 0.4808\n",
            "Epoch 2/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4363 - val_loss: nan - val_accuracy: 0.3917\n",
            "Epoch 3/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4243 - val_loss: nan - val_accuracy: 0.3917\n",
            "Epoch 4/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4243 - val_loss: nan - val_accuracy: 0.3917\n",
            "Epoch 5/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4243 - val_loss: nan - val_accuracy: 0.3917\n",
            "Epoch 6/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4243 - val_loss: nan - val_accuracy: 0.3917\n",
            "Epoch 7/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4243 - val_loss: nan - val_accuracy: 0.3917\n",
            "Epoch 8/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4243 - val_loss: nan - val_accuracy: 0.3917\n",
            "Epoch 9/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4243 - val_loss: nan - val_accuracy: 0.3917\n",
            "Epoch 10/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4243 - val_loss: nan - val_accuracy: 0.3917\n",
            "Epoch 11/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4243 - val_loss: nan - val_accuracy: 0.3917\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00011: early stopping\n",
            "Test Accuracy: 48.08333218097687\n",
            "Epoch 1/100\n",
            "216/216 - 28s - loss: -5.0459e+13 - accuracy: 0.3917 - val_loss: -1.5643e+15 - val_accuracy: 0.4642\n",
            "Epoch 2/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4445 - val_loss: nan - val_accuracy: 0.4192\n",
            "Epoch 3/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4212 - val_loss: nan - val_accuracy: 0.4192\n",
            "Epoch 4/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4212 - val_loss: nan - val_accuracy: 0.4192\n",
            "Epoch 5/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4212 - val_loss: nan - val_accuracy: 0.4192\n",
            "Epoch 6/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4212 - val_loss: nan - val_accuracy: 0.4192\n",
            "Epoch 7/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4212 - val_loss: nan - val_accuracy: 0.4192\n",
            "Epoch 8/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4212 - val_loss: nan - val_accuracy: 0.4192\n",
            "Epoch 9/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4212 - val_loss: nan - val_accuracy: 0.4192\n",
            "Epoch 10/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4212 - val_loss: nan - val_accuracy: 0.4192\n",
            "Epoch 11/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4212 - val_loss: nan - val_accuracy: 0.4192\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00011: early stopping\n",
            "Test Accuracy: 46.416667103767395\n",
            "Epoch 1/100\n",
            "216/216 - 28s - loss: -3.3144e+14 - accuracy: 0.3849 - val_loss: -4.6150e+15 - val_accuracy: 0.4500\n",
            "Epoch 2/100\n",
            "216/216 - 26s - loss: nan - accuracy: 0.4194 - val_loss: nan - val_accuracy: 0.4258\n",
            "Epoch 3/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4205 - val_loss: nan - val_accuracy: 0.4258\n",
            "Epoch 4/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4205 - val_loss: nan - val_accuracy: 0.4258\n",
            "Epoch 5/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4205 - val_loss: nan - val_accuracy: 0.4258\n",
            "Epoch 6/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4205 - val_loss: nan - val_accuracy: 0.4258\n",
            "Epoch 7/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4205 - val_loss: nan - val_accuracy: 0.4258\n",
            "Epoch 8/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4205 - val_loss: nan - val_accuracy: 0.4258\n",
            "Epoch 9/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4205 - val_loss: nan - val_accuracy: 0.4258\n",
            "Epoch 10/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4205 - val_loss: nan - val_accuracy: 0.4258\n",
            "Epoch 11/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4205 - val_loss: nan - val_accuracy: 0.4258\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00011: early stopping\n",
            "Test Accuracy: 44.999998807907104\n",
            "Epoch 1/100\n",
            "216/216 - 28s - loss: -1.8832e+13 - accuracy: 0.3955 - val_loss: -1.1203e+15 - val_accuracy: 0.4700\n",
            "Epoch 2/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4435 - val_loss: nan - val_accuracy: 0.4192\n",
            "Epoch 3/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4212 - val_loss: nan - val_accuracy: 0.4192\n",
            "Epoch 4/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4212 - val_loss: nan - val_accuracy: 0.4192\n",
            "Epoch 5/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4212 - val_loss: nan - val_accuracy: 0.4192\n",
            "Epoch 6/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4212 - val_loss: nan - val_accuracy: 0.4192\n",
            "Epoch 7/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4212 - val_loss: nan - val_accuracy: 0.4192\n",
            "Epoch 8/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4212 - val_loss: nan - val_accuracy: 0.4192\n",
            "Epoch 9/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4212 - val_loss: nan - val_accuracy: 0.4192\n",
            "Epoch 10/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4212 - val_loss: nan - val_accuracy: 0.4192\n",
            "Epoch 11/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4212 - val_loss: nan - val_accuracy: 0.4192\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00011: early stopping\n",
            "Test Accuracy: 46.99999988079071\n",
            "Epoch 1/100\n",
            "216/216 - 28s - loss: -1.0425e+15 - accuracy: 0.3919 - val_loss: -3.5918e+16 - val_accuracy: 0.4667\n",
            "Epoch 2/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4348 - val_loss: nan - val_accuracy: 0.4142\n",
            "Epoch 3/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4218 - val_loss: nan - val_accuracy: 0.4142\n",
            "Epoch 4/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4218 - val_loss: nan - val_accuracy: 0.4142\n",
            "Epoch 5/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4218 - val_loss: nan - val_accuracy: 0.4142\n",
            "Epoch 6/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4218 - val_loss: nan - val_accuracy: 0.4142\n",
            "Epoch 7/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4218 - val_loss: nan - val_accuracy: 0.4142\n",
            "Epoch 8/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4218 - val_loss: nan - val_accuracy: 0.4142\n",
            "Epoch 9/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4218 - val_loss: nan - val_accuracy: 0.4142\n",
            "Epoch 10/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4218 - val_loss: nan - val_accuracy: 0.4142\n",
            "Epoch 11/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4218 - val_loss: nan - val_accuracy: 0.4142\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00011: early stopping\n",
            "Test Accuracy: 46.666666865348816\n",
            "Epoch 1/100\n",
            "216/216 - 29s - loss: -4.0402e+14 - accuracy: 0.3782 - val_loss: -1.2454e+16 - val_accuracy: 0.4475\n",
            "Epoch 2/100\n",
            "216/216 - 26s - loss: nan - accuracy: 0.4261 - val_loss: nan - val_accuracy: 0.4308\n",
            "Epoch 3/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4199 - val_loss: nan - val_accuracy: 0.4308\n",
            "Epoch 4/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4199 - val_loss: nan - val_accuracy: 0.4308\n",
            "Epoch 5/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4199 - val_loss: nan - val_accuracy: 0.4308\n",
            "Epoch 6/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4199 - val_loss: nan - val_accuracy: 0.4308\n",
            "Epoch 7/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4199 - val_loss: nan - val_accuracy: 0.4308\n",
            "Epoch 8/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4199 - val_loss: nan - val_accuracy: 0.4308\n",
            "Epoch 9/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4199 - val_loss: nan - val_accuracy: 0.4308\n",
            "Epoch 10/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4199 - val_loss: nan - val_accuracy: 0.4308\n",
            "Epoch 11/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4199 - val_loss: nan - val_accuracy: 0.4308\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00011: early stopping\n",
            "Test Accuracy: 44.749999046325684\n",
            "\n",
            "  Activation Filters       acc1  ...       acc9      acc10        AVG\n",
            "0       relu       1  46.666667  ...  48.750001  47.416666  46.633333\n",
            "1       relu       2  47.166666  ...  46.666667  44.749999  47.033333\n",
            "\n",
            "[2 rows x 13 columns]\n",
            "\n",
            "-------------------------------------------\n",
            "Training 3: relu activation, 3 kernel size.\n",
            "-------------------------------------------\n",
            "Epoch 1/100\n",
            "216/216 - 29s - loss: -2.6472e+14 - accuracy: 0.3795 - val_loss: -7.5350e+15 - val_accuracy: 0.4292\n",
            "Epoch 2/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4247 - val_loss: nan - val_accuracy: 0.4100\n",
            "Epoch 3/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4222 - val_loss: nan - val_accuracy: 0.4100\n",
            "Epoch 4/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4222 - val_loss: nan - val_accuracy: 0.4100\n",
            "Epoch 5/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4222 - val_loss: nan - val_accuracy: 0.4100\n",
            "Epoch 6/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4222 - val_loss: nan - val_accuracy: 0.4100\n",
            "Epoch 7/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4222 - val_loss: nan - val_accuracy: 0.4100\n",
            "Epoch 8/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4222 - val_loss: nan - val_accuracy: 0.4100\n",
            "Epoch 9/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4222 - val_loss: nan - val_accuracy: 0.4100\n",
            "Epoch 10/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4222 - val_loss: nan - val_accuracy: 0.4100\n",
            "Epoch 11/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4222 - val_loss: nan - val_accuracy: 0.4100\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00011: early stopping\n",
            "Test Accuracy: 42.916667461395264\n",
            "Epoch 1/100\n",
            "216/216 - 23s - loss: -2.1389e+14 - accuracy: 0.3864 - val_loss: -1.9810e+15 - val_accuracy: 0.3542\n",
            "Epoch 2/100\n",
            "216/216 - 21s - loss: nan - accuracy: 0.4264 - val_loss: nan - val_accuracy: 0.4275\n",
            "Epoch 3/100\n",
            "216/216 - 20s - loss: nan - accuracy: 0.4203 - val_loss: nan - val_accuracy: 0.4275\n",
            "Epoch 4/100\n",
            "216/216 - 20s - loss: nan - accuracy: 0.4203 - val_loss: nan - val_accuracy: 0.4275\n",
            "Epoch 5/100\n",
            "216/216 - 20s - loss: nan - accuracy: 0.4203 - val_loss: nan - val_accuracy: 0.4275\n",
            "Epoch 6/100\n",
            "216/216 - 20s - loss: nan - accuracy: 0.4203 - val_loss: nan - val_accuracy: 0.4275\n",
            "Epoch 7/100\n",
            "216/216 - 20s - loss: nan - accuracy: 0.4203 - val_loss: nan - val_accuracy: 0.4275\n",
            "Epoch 8/100\n",
            "216/216 - 20s - loss: nan - accuracy: 0.4203 - val_loss: nan - val_accuracy: 0.4275\n",
            "Epoch 9/100\n",
            "216/216 - 20s - loss: nan - accuracy: 0.4203 - val_loss: nan - val_accuracy: 0.4275\n",
            "Epoch 10/100\n",
            "216/216 - 20s - loss: nan - accuracy: 0.4203 - val_loss: nan - val_accuracy: 0.4275\n",
            "Epoch 11/100\n",
            "216/216 - 20s - loss: nan - accuracy: 0.4203 - val_loss: nan - val_accuracy: 0.4275\n",
            "Epoch 12/100\n",
            "216/216 - 20s - loss: nan - accuracy: 0.4203 - val_loss: nan - val_accuracy: 0.4275\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00012: early stopping\n",
            "Test Accuracy: 42.750000953674316\n",
            "Epoch 1/100\n",
            "216/216 - 28s - loss: -6.7210e+14 - accuracy: 0.3887 - val_loss: -3.6073e+16 - val_accuracy: 0.4367\n",
            "Epoch 2/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4293 - val_loss: nan - val_accuracy: 0.3900\n",
            "Epoch 3/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4244 - val_loss: nan - val_accuracy: 0.3900\n",
            "Epoch 4/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4244 - val_loss: nan - val_accuracy: 0.3900\n",
            "Epoch 5/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4244 - val_loss: nan - val_accuracy: 0.3900\n",
            "Epoch 6/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4244 - val_loss: nan - val_accuracy: 0.3900\n",
            "Epoch 7/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4244 - val_loss: nan - val_accuracy: 0.3900\n",
            "Epoch 8/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4244 - val_loss: nan - val_accuracy: 0.3900\n",
            "Epoch 9/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4244 - val_loss: nan - val_accuracy: 0.3900\n",
            "Epoch 10/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4244 - val_loss: nan - val_accuracy: 0.3900\n",
            "Epoch 11/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4244 - val_loss: nan - val_accuracy: 0.3900\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00011: early stopping\n",
            "Test Accuracy: 43.666666746139526\n",
            "Epoch 1/100\n",
            "216/216 - 29s - loss: -5.3705e+13 - accuracy: 0.3826 - val_loss: -2.4291e+15 - val_accuracy: 0.4625\n",
            "Epoch 2/100\n",
            "216/216 - 26s - loss: nan - accuracy: 0.4392 - val_loss: nan - val_accuracy: 0.4075\n",
            "Epoch 3/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4225 - val_loss: nan - val_accuracy: 0.4075\n",
            "Epoch 4/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4225 - val_loss: nan - val_accuracy: 0.4075\n",
            "Epoch 5/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4225 - val_loss: nan - val_accuracy: 0.4075\n",
            "Epoch 6/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4225 - val_loss: nan - val_accuracy: 0.4075\n",
            "Epoch 7/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4225 - val_loss: nan - val_accuracy: 0.4075\n",
            "Epoch 8/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4225 - val_loss: nan - val_accuracy: 0.4075\n",
            "Epoch 9/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4225 - val_loss: nan - val_accuracy: 0.4075\n",
            "Epoch 10/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4225 - val_loss: nan - val_accuracy: 0.4075\n",
            "Epoch 11/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4225 - val_loss: nan - val_accuracy: 0.4075\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00011: early stopping\n",
            "Test Accuracy: 46.25000059604645\n",
            "Epoch 1/100\n",
            "216/216 - 28s - loss: -1.9065e+12 - accuracy: 0.3869 - val_loss: -9.6143e+13 - val_accuracy: 0.5033\n",
            "Epoch 2/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4502 - val_loss: nan - val_accuracy: 0.4117\n",
            "Epoch 3/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4220 - val_loss: nan - val_accuracy: 0.4117\n",
            "Epoch 4/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4220 - val_loss: nan - val_accuracy: 0.4117\n",
            "Epoch 5/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4220 - val_loss: nan - val_accuracy: 0.4117\n",
            "Epoch 6/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4220 - val_loss: nan - val_accuracy: 0.4117\n",
            "Epoch 7/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4220 - val_loss: nan - val_accuracy: 0.4117\n",
            "Epoch 8/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4220 - val_loss: nan - val_accuracy: 0.4117\n",
            "Epoch 9/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4220 - val_loss: nan - val_accuracy: 0.4117\n",
            "Epoch 10/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4220 - val_loss: nan - val_accuracy: 0.4117\n",
            "Epoch 11/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4220 - val_loss: nan - val_accuracy: 0.4117\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00011: early stopping\n",
            "Test Accuracy: 50.333333015441895\n",
            "Epoch 1/100\n",
            "216/216 - 28s - loss: -2.4913e+13 - accuracy: 0.3919 - val_loss: -1.1069e+15 - val_accuracy: 0.4758\n",
            "Epoch 2/100\n",
            "216/216 - 26s - loss: nan - accuracy: 0.4440 - val_loss: nan - val_accuracy: 0.4217\n",
            "Epoch 3/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4209 - val_loss: nan - val_accuracy: 0.4217\n",
            "Epoch 4/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4209 - val_loss: nan - val_accuracy: 0.4217\n",
            "Epoch 5/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4209 - val_loss: nan - val_accuracy: 0.4217\n",
            "Epoch 6/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4209 - val_loss: nan - val_accuracy: 0.4217\n",
            "Epoch 7/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4209 - val_loss: nan - val_accuracy: 0.4217\n",
            "Epoch 8/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4209 - val_loss: nan - val_accuracy: 0.4217\n",
            "Epoch 9/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4209 - val_loss: nan - val_accuracy: 0.4217\n",
            "Epoch 10/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4209 - val_loss: nan - val_accuracy: 0.4217\n",
            "Epoch 11/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4209 - val_loss: nan - val_accuracy: 0.4217\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00011: early stopping\n",
            "Test Accuracy: 47.583332657814026\n",
            "Epoch 1/100\n",
            "216/216 - 28s - loss: -7.9534e+14 - accuracy: 0.4002 - val_loss: -3.0753e+16 - val_accuracy: 0.4583\n",
            "Epoch 2/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4278 - val_loss: nan - val_accuracy: 0.4450\n",
            "Epoch 3/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4183 - val_loss: nan - val_accuracy: 0.4450\n",
            "Epoch 4/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4183 - val_loss: nan - val_accuracy: 0.4450\n",
            "Epoch 5/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4183 - val_loss: nan - val_accuracy: 0.4450\n",
            "Epoch 6/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4183 - val_loss: nan - val_accuracy: 0.4450\n",
            "Epoch 7/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4183 - val_loss: nan - val_accuracy: 0.4450\n",
            "Epoch 8/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4183 - val_loss: nan - val_accuracy: 0.4450\n",
            "Epoch 9/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4183 - val_loss: nan - val_accuracy: 0.4450\n",
            "Epoch 10/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4183 - val_loss: nan - val_accuracy: 0.4450\n",
            "Epoch 11/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4183 - val_loss: nan - val_accuracy: 0.4450\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00011: early stopping\n",
            "Test Accuracy: 45.83333432674408\n",
            "Epoch 1/100\n",
            "216/216 - 29s - loss: -1.4687e+15 - accuracy: 0.3954 - val_loss: -4.0856e+16 - val_accuracy: 0.4392\n",
            "Epoch 2/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4364 - val_loss: nan - val_accuracy: 0.4283\n",
            "Epoch 3/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4202 - val_loss: nan - val_accuracy: 0.4283\n",
            "Epoch 4/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4202 - val_loss: nan - val_accuracy: 0.4283\n",
            "Epoch 5/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4202 - val_loss: nan - val_accuracy: 0.4283\n",
            "Epoch 6/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4202 - val_loss: nan - val_accuracy: 0.4283\n",
            "Epoch 7/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4202 - val_loss: nan - val_accuracy: 0.4283\n",
            "Epoch 8/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4202 - val_loss: nan - val_accuracy: 0.4283\n",
            "Epoch 9/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4202 - val_loss: nan - val_accuracy: 0.4283\n",
            "Epoch 10/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4202 - val_loss: nan - val_accuracy: 0.4283\n",
            "Epoch 11/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4202 - val_loss: nan - val_accuracy: 0.4283\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00011: early stopping\n",
            "Test Accuracy: 43.91666650772095\n",
            "Epoch 1/100\n",
            "216/216 - 29s - loss: -7.0802e+14 - accuracy: 0.3957 - val_loss: -2.7600e+16 - val_accuracy: 0.4575\n",
            "Epoch 2/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4235 - val_loss: nan - val_accuracy: 0.4375\n",
            "Epoch 3/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4192 - val_loss: nan - val_accuracy: 0.4375\n",
            "Epoch 4/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4192 - val_loss: nan - val_accuracy: 0.4375\n",
            "Epoch 5/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4192 - val_loss: nan - val_accuracy: 0.4375\n",
            "Epoch 6/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4192 - val_loss: nan - val_accuracy: 0.4375\n",
            "Epoch 7/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4192 - val_loss: nan - val_accuracy: 0.4375\n",
            "Epoch 8/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4192 - val_loss: nan - val_accuracy: 0.4375\n",
            "Epoch 9/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4192 - val_loss: nan - val_accuracy: 0.4375\n",
            "Epoch 10/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4192 - val_loss: nan - val_accuracy: 0.4375\n",
            "Epoch 11/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4192 - val_loss: nan - val_accuracy: 0.4375\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00011: early stopping\n",
            "Test Accuracy: 45.750001072883606\n",
            "Epoch 1/100\n",
            "216/216 - 28s - loss: -1.4431e+14 - accuracy: 0.3833 - val_loss: -5.3720e+15 - val_accuracy: 0.4583\n",
            "Epoch 2/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4265 - val_loss: nan - val_accuracy: 0.4308\n",
            "Epoch 3/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4199 - val_loss: nan - val_accuracy: 0.4308\n",
            "Epoch 4/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4199 - val_loss: nan - val_accuracy: 0.4308\n",
            "Epoch 5/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4199 - val_loss: nan - val_accuracy: 0.4308\n",
            "Epoch 6/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4199 - val_loss: nan - val_accuracy: 0.4308\n",
            "Epoch 7/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4199 - val_loss: nan - val_accuracy: 0.4308\n",
            "Epoch 8/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4199 - val_loss: nan - val_accuracy: 0.4308\n",
            "Epoch 9/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4199 - val_loss: nan - val_accuracy: 0.4308\n",
            "Epoch 10/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4199 - val_loss: nan - val_accuracy: 0.4308\n",
            "Epoch 11/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4199 - val_loss: nan - val_accuracy: 0.4308\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00011: early stopping\n",
            "Test Accuracy: 45.83333432674408\n",
            "\n",
            "  Activation Filters       acc1  ...       acc9      acc10        AVG\n",
            "0       relu       1  46.666667  ...  48.750001  47.416666  46.633333\n",
            "1       relu       2  47.166666  ...  46.666667  44.749999  47.033333\n",
            "2       relu       3  42.916667  ...  45.750001  45.833334  45.483334\n",
            "\n",
            "[3 rows x 13 columns]\n",
            "\n",
            "-------------------------------------------\n",
            "Training 4: relu activation, 4 kernel size.\n",
            "-------------------------------------------\n",
            "Epoch 1/100\n",
            "216/216 - 23s - loss: -1.3984e+14 - accuracy: 0.3862 - val_loss: -5.6601e+15 - val_accuracy: 0.4892\n",
            "Epoch 2/100\n",
            "216/216 - 20s - loss: nan - accuracy: 0.4199 - val_loss: nan - val_accuracy: 0.4392\n",
            "Epoch 3/100\n",
            "216/216 - 20s - loss: nan - accuracy: 0.4190 - val_loss: nan - val_accuracy: 0.4392\n",
            "Epoch 4/100\n",
            "216/216 - 20s - loss: nan - accuracy: 0.4190 - val_loss: nan - val_accuracy: 0.4392\n",
            "Epoch 5/100\n",
            "216/216 - 20s - loss: nan - accuracy: 0.4190 - val_loss: nan - val_accuracy: 0.4392\n",
            "Epoch 6/100\n",
            "216/216 - 20s - loss: nan - accuracy: 0.4190 - val_loss: nan - val_accuracy: 0.4392\n",
            "Epoch 7/100\n",
            "216/216 - 20s - loss: nan - accuracy: 0.4190 - val_loss: nan - val_accuracy: 0.4392\n",
            "Epoch 8/100\n",
            "216/216 - 20s - loss: nan - accuracy: 0.4190 - val_loss: nan - val_accuracy: 0.4392\n",
            "Epoch 9/100\n",
            "216/216 - 20s - loss: nan - accuracy: 0.4190 - val_loss: nan - val_accuracy: 0.4392\n",
            "Epoch 10/100\n",
            "216/216 - 20s - loss: nan - accuracy: 0.4190 - val_loss: nan - val_accuracy: 0.4392\n",
            "Epoch 11/100\n",
            "216/216 - 20s - loss: nan - accuracy: 0.4190 - val_loss: nan - val_accuracy: 0.4392\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00011: early stopping\n",
            "Test Accuracy: 48.91666769981384\n",
            "Epoch 1/100\n",
            "216/216 - 28s - loss: -5.1438e+13 - accuracy: 0.3832 - val_loss: -1.5763e+15 - val_accuracy: 0.4300\n",
            "Epoch 2/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4288 - val_loss: nan - val_accuracy: 0.4550\n",
            "Epoch 3/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4172 - val_loss: nan - val_accuracy: 0.4550\n",
            "Epoch 4/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4172 - val_loss: nan - val_accuracy: 0.4550\n",
            "Epoch 5/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4172 - val_loss: nan - val_accuracy: 0.4550\n",
            "Epoch 6/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4172 - val_loss: nan - val_accuracy: 0.4550\n",
            "Epoch 7/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4172 - val_loss: nan - val_accuracy: 0.4550\n",
            "Epoch 8/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4172 - val_loss: nan - val_accuracy: 0.4550\n",
            "Epoch 9/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4172 - val_loss: nan - val_accuracy: 0.4550\n",
            "Epoch 10/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4172 - val_loss: nan - val_accuracy: 0.4550\n",
            "Epoch 11/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4172 - val_loss: nan - val_accuracy: 0.4550\n",
            "Epoch 12/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4172 - val_loss: nan - val_accuracy: 0.4550\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00012: early stopping\n",
            "Test Accuracy: 45.500001311302185\n",
            "Epoch 1/100\n",
            "216/216 - 28s - loss: -2.1908e+14 - accuracy: 0.3816 - val_loss: -1.3459e+16 - val_accuracy: 0.4600\n",
            "Epoch 2/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4256 - val_loss: nan - val_accuracy: 0.3992\n",
            "Epoch 3/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4234 - val_loss: nan - val_accuracy: 0.3992\n",
            "Epoch 4/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4234 - val_loss: nan - val_accuracy: 0.3992\n",
            "Epoch 5/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4234 - val_loss: nan - val_accuracy: 0.3992\n",
            "Epoch 6/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4234 - val_loss: nan - val_accuracy: 0.3992\n",
            "Epoch 7/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4234 - val_loss: nan - val_accuracy: 0.3992\n",
            "Epoch 8/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4234 - val_loss: nan - val_accuracy: 0.3992\n",
            "Epoch 9/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4234 - val_loss: nan - val_accuracy: 0.3992\n",
            "Epoch 10/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4234 - val_loss: nan - val_accuracy: 0.3992\n",
            "Epoch 11/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4234 - val_loss: nan - val_accuracy: 0.3992\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00011: early stopping\n",
            "Test Accuracy: 46.00000083446503\n",
            "Epoch 1/100\n",
            "216/216 - 28s - loss: -1.8298e+12 - accuracy: 0.3892 - val_loss: -1.1789e+14 - val_accuracy: 0.4808\n",
            "Epoch 2/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4484 - val_loss: nan - val_accuracy: 0.3967\n",
            "Epoch 3/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4237 - val_loss: nan - val_accuracy: 0.3967\n",
            "Epoch 4/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4237 - val_loss: nan - val_accuracy: 0.3967\n",
            "Epoch 5/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4237 - val_loss: nan - val_accuracy: 0.3967\n",
            "Epoch 6/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4237 - val_loss: nan - val_accuracy: 0.3967\n",
            "Epoch 7/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4237 - val_loss: nan - val_accuracy: 0.3967\n",
            "Epoch 8/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4237 - val_loss: nan - val_accuracy: 0.3967\n",
            "Epoch 9/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4237 - val_loss: nan - val_accuracy: 0.3967\n",
            "Epoch 10/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4237 - val_loss: nan - val_accuracy: 0.3967\n",
            "Epoch 11/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4237 - val_loss: nan - val_accuracy: 0.3967\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00011: early stopping\n",
            "Test Accuracy: 48.08333218097687\n",
            "Epoch 1/100\n",
            "216/216 - 29s - loss: -6.5064e+13 - accuracy: 0.3997 - val_loss: -2.4166e+15 - val_accuracy: 0.4658\n",
            "Epoch 2/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4357 - val_loss: nan - val_accuracy: 0.4158\n",
            "Epoch 3/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4216 - val_loss: nan - val_accuracy: 0.4158\n",
            "Epoch 4/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4216 - val_loss: nan - val_accuracy: 0.4158\n",
            "Epoch 5/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4216 - val_loss: nan - val_accuracy: 0.4158\n",
            "Epoch 6/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4216 - val_loss: nan - val_accuracy: 0.4158\n",
            "Epoch 7/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4216 - val_loss: nan - val_accuracy: 0.4158\n",
            "Epoch 8/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4216 - val_loss: nan - val_accuracy: 0.4158\n",
            "Epoch 9/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4216 - val_loss: nan - val_accuracy: 0.4158\n",
            "Epoch 10/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4216 - val_loss: nan - val_accuracy: 0.4158\n",
            "Epoch 11/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4216 - val_loss: nan - val_accuracy: 0.4158\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00011: early stopping\n",
            "Test Accuracy: 46.58333361148834\n",
            "Epoch 1/100\n",
            "216/216 - 28s - loss: -3.7525e+13 - accuracy: 0.3768 - val_loss: -8.8081e+14 - val_accuracy: 0.3833\n",
            "Epoch 2/100\n",
            "216/216 - 26s - loss: nan - accuracy: 0.4287 - val_loss: nan - val_accuracy: 0.4392\n",
            "Epoch 3/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4190 - val_loss: nan - val_accuracy: 0.4392\n",
            "Epoch 4/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4190 - val_loss: nan - val_accuracy: 0.4392\n",
            "Epoch 5/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4190 - val_loss: nan - val_accuracy: 0.4392\n",
            "Epoch 6/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4190 - val_loss: nan - val_accuracy: 0.4392\n",
            "Epoch 7/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4190 - val_loss: nan - val_accuracy: 0.4392\n",
            "Epoch 8/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4190 - val_loss: nan - val_accuracy: 0.4392\n",
            "Epoch 9/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4190 - val_loss: nan - val_accuracy: 0.4392\n",
            "Epoch 10/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4190 - val_loss: nan - val_accuracy: 0.4392\n",
            "Epoch 11/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4190 - val_loss: nan - val_accuracy: 0.4392\n",
            "Epoch 12/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4190 - val_loss: nan - val_accuracy: 0.4392\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00012: early stopping\n",
            "Test Accuracy: 43.91666650772095\n",
            "Epoch 1/100\n",
            "216/216 - 28s - loss: -5.9712e+14 - accuracy: 0.3973 - val_loss: -2.3847e+16 - val_accuracy: 0.4708\n",
            "Epoch 2/100\n",
            "216/216 - 26s - loss: nan - accuracy: 0.4346 - val_loss: nan - val_accuracy: 0.4050\n",
            "Epoch 3/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4228 - val_loss: nan - val_accuracy: 0.4050\n",
            "Epoch 4/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4228 - val_loss: nan - val_accuracy: 0.4050\n",
            "Epoch 5/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4228 - val_loss: nan - val_accuracy: 0.4050\n",
            "Epoch 6/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4228 - val_loss: nan - val_accuracy: 0.4050\n",
            "Epoch 7/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4228 - val_loss: nan - val_accuracy: 0.4050\n",
            "Epoch 8/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4228 - val_loss: nan - val_accuracy: 0.4050\n",
            "Epoch 9/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4228 - val_loss: nan - val_accuracy: 0.4050\n",
            "Epoch 10/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4228 - val_loss: nan - val_accuracy: 0.4050\n",
            "Epoch 11/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4228 - val_loss: nan - val_accuracy: 0.4050\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00011: early stopping\n",
            "Test Accuracy: 47.083333134651184\n",
            "Epoch 1/100\n",
            "216/216 - 28s - loss: -2.1631e+14 - accuracy: 0.3909 - val_loss: -7.8579e+15 - val_accuracy: 0.3442\n",
            "Epoch 2/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4258 - val_loss: nan - val_accuracy: 0.4258\n",
            "Epoch 3/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4205 - val_loss: nan - val_accuracy: 0.4258\n",
            "Epoch 4/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4205 - val_loss: nan - val_accuracy: 0.4258\n",
            "Epoch 5/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4205 - val_loss: nan - val_accuracy: 0.4258\n",
            "Epoch 6/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4205 - val_loss: nan - val_accuracy: 0.4258\n",
            "Epoch 7/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4205 - val_loss: nan - val_accuracy: 0.4258\n",
            "Epoch 8/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4205 - val_loss: nan - val_accuracy: 0.4258\n",
            "Epoch 9/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4205 - val_loss: nan - val_accuracy: 0.4258\n",
            "Epoch 10/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4205 - val_loss: nan - val_accuracy: 0.4258\n",
            "Epoch 11/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4205 - val_loss: nan - val_accuracy: 0.4258\n",
            "Epoch 12/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4205 - val_loss: nan - val_accuracy: 0.4258\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00012: early stopping\n",
            "Test Accuracy: 42.58333444595337\n",
            "Epoch 1/100\n",
            "216/216 - 28s - loss: -6.5782e+14 - accuracy: 0.3813 - val_loss: -3.0549e+16 - val_accuracy: 0.3608\n",
            "Epoch 2/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4259 - val_loss: nan - val_accuracy: 0.4083\n",
            "Epoch 3/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4224 - val_loss: nan - val_accuracy: 0.4083\n",
            "Epoch 4/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4224 - val_loss: nan - val_accuracy: 0.4083\n",
            "Epoch 5/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4224 - val_loss: nan - val_accuracy: 0.4083\n",
            "Epoch 6/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4224 - val_loss: nan - val_accuracy: 0.4083\n",
            "Epoch 7/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4224 - val_loss: nan - val_accuracy: 0.4083\n",
            "Epoch 8/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4224 - val_loss: nan - val_accuracy: 0.4083\n",
            "Epoch 9/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4224 - val_loss: nan - val_accuracy: 0.4083\n",
            "Epoch 10/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4224 - val_loss: nan - val_accuracy: 0.4083\n",
            "Epoch 11/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4224 - val_loss: nan - val_accuracy: 0.4083\n",
            "Epoch 12/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4224 - val_loss: nan - val_accuracy: 0.4083\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00012: early stopping\n",
            "Test Accuracy: 40.833333134651184\n",
            "Epoch 1/100\n",
            "216/216 - 28s - loss: -1.2342e+08 - accuracy: 0.3631 - val_loss: -2.2346e+10 - val_accuracy: 0.4383\n",
            "Epoch 2/100\n",
            "216/216 - 26s - loss: nan - accuracy: 0.4226 - val_loss: nan - val_accuracy: 0.4258\n",
            "Epoch 3/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4205 - val_loss: nan - val_accuracy: 0.4258\n",
            "Epoch 4/100\n",
            "216/216 - 25s - loss: nan - accuracy: 0.4205 - val_loss: nan - val_accuracy: 0.4258\n",
            "Epoch 5/100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQfI6On3G4D2"
      },
      "source": [
        "record.sort_values(by='AVG', ascending=False)\n",
        "record[['Activation', 'AVG']].groupby(by='Activation').max().sort_values(by='AVG', ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYjkGQFa_b92"
      },
      "source": [
        "report = record.sort_values(by='AVG', ascending=False)\n",
        "report = report.to_excel('TCN_CR.xlsx', sheet_name='random')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEitfwvjMktd"
      },
      "source": [
        "**With Upsampling of One Class**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWHcopV1NXWH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "outputId": "62b40beb-0747-4e0a-f659-f2515211a147"
      },
      "source": [
        "df.groupby(by = 'level').count()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Comments</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>level</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2708</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Comments\n",
              "level          \n",
              "0          5052\n",
              "1          4240\n",
              "2          2708"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "rsavPEw3FeaC",
        "outputId": "ac9ba655-7d39-40f6-b12f-634e8eb3a5fa"
      },
      "source": [
        "\n",
        "df['level'].value_counts().plot.bar()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f1be7126f10>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRNSmxSSGa6-"
      },
      "source": [
        "Since, the gap is visible I've tried Up Sampling 2 to have a more distributed model using SMOTE Technique so as to not overfit the model\n",
        "\n",
        "**IT HASN\"T BEEN RUN YET**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8LjnH-jGWzQ"
      },
      "source": [
        "/*from sklearn.model_selection import train_test_split\n",
        "X = comments\n",
        "y = level\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)*/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-MbkEt3J5pU"
      },
      "source": [
        "# THIS IS SMOTE SECTION\n",
        "\n",
        "**The code is below, derieved from SMOTE PAPER however hasn't been implemented yet**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j085QthZHC7o"
      },
      "source": [
        "def resamplingDataPrep(X_train, y_train, y_test): \n",
        "    # concatenate our training data back together\n",
        "    resampling = X_train.copy()\n",
        "    resampling[y_test] = y_train.values\n",
        "    # separate minority and majority classes\n",
        "    majority_class = resampling[resampling[y_test]==0]\n",
        "    minority_class = resampling[resampling[y_test]==1]\n",
        "    # Get a class count to understand the class imbalance.\n",
        "    print('majority_class: '+ str(len(majority_class)))\n",
        "    print('minority_class: '+ str(len(minority_class)))\n",
        "    return majority_class, minority_class\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5YgO8bMHgIZ",
        "outputId": "aff90a10-a1f6-4b53-b606-0730579627db"
      },
      "source": [
        "def upsample_SMOTE(X_train, y_train, ratio=1.0):\n",
        "    \"\"\"Upsamples minority class using SMOTE.\n",
        "    Ratio argument is the percentage of the upsampled minority class in relation\n",
        "    to the majority class. Default is 1.0\n",
        "    \"\"\"\n",
        "    sm = SMOTE(random_state=23, sampling_strategy=ratio)\n",
        "    X_train_sm, y_train_sm = sm.fit_resample(X_train, y_train)\n",
        "    print(len(X_train_sm), len(y_train_sm))\n",
        "    return X_train_sm, y_train_sm\n",
        "print('Cool')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cool\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhKH4y5gH0fF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUzNFajTIuiA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}